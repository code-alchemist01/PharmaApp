"""
Turkish Pill Model (150 sƒ±nƒ±f) ‚Üí ONNX D√∂n√º≈üt√ºrme Scripti
Hugging Face formatƒ±ndaki modeli ONNX formatƒ±na d√∂n√º≈üt√ºr√ºr
"""

import torch
from transformers import ViTForImageClassification, ViTImageProcessor
import onnx
from onnxruntime.quantization import quantize_dynamic, QuantType
import os
from pathlib import Path

# Model yolu
MODEL_PATH = r"C:\Users\excalibur\Desktop\Projeler\AI Real Project\turkish_pill\models\classification\checkpoint-10350"
OUTPUT_DIR = r"C:\Users\excalibur\Desktop\Projeler\AI Real Project\turkish_pill\models\classification"
ONNX_MODEL_PATH = os.path.join(OUTPUT_DIR, "classification_150.onnx")
ONNX_QUANTIZED_PATH = os.path.join(OUTPUT_DIR, "classification_150_quantized.onnx")

def convert_to_onnx():
    """Hugging Face modelini ONNX formatƒ±na d√∂n√º≈üt√ºr"""
    
    print("=" * 60)
    print("Turkish Pill Model ‚Üí ONNX D√∂n√º≈üt√ºrme")
    print("=" * 60)
    
    # 1. Model y√ºkle
    print("\n[1/5] Model y√ºkleniyor...")
    try:
        model = ViTForImageClassification.from_pretrained(MODEL_PATH)
        model.eval()
        print(f"‚úÖ Model y√ºklendi: {MODEL_PATH}")
        print(f"   Sƒ±nƒ±f sayƒ±sƒ±: {model.config.num_labels}")
    except Exception as e:
        print(f"‚ùå Model y√ºkleme hatasƒ±: {e}")
        return False
    
    # 2. Dummy input olu≈ütur
    print("\n[2/5] Dummy input olu≈üturuluyor...")
    # ViT input: [batch, channels, height, width] = [1, 3, 224, 224]
    dummy_input = torch.randn(1, 3, 224, 224)
    print(f"‚úÖ Dummy input: {dummy_input.shape}")
    
    # 3. ONNX'a d√∂n√º≈üt√ºr
    print("\n[3/5] ONNX formatƒ±na d√∂n√º≈üt√ºr√ºl√ºyor...")
    try:
        torch.onnx.export(
            model,
            dummy_input,
            ONNX_MODEL_PATH,
            input_names=['pixel_values'],
            output_names=['logits'],
            dynamic_axes={
                'pixel_values': {0: 'batch'},
                'logits': {0: 'batch'}
            },
            opset_version=11,
            do_constant_folding=True,
            verbose=False
        )
        
        # Model boyutunu kontrol et
        model_size_mb = os.path.getsize(ONNX_MODEL_PATH) / (1024 * 1024)
        print(f"‚úÖ ONNX model olu≈üturuldu: {ONNX_MODEL_PATH}")
        print(f"   Model boyutu: {model_size_mb:.2f} MB")
    except Exception as e:
        print(f"‚ùå ONNX d√∂n√º≈üt√ºrme hatasƒ±: {e}")
        return False
    
    # 4. ONNX modelini doƒürula
    print("\n[4/5] ONNX model doƒürulanƒ±yor...")
    try:
        onnx_model = onnx.load(ONNX_MODEL_PATH)
        onnx.checker.check_model(onnx_model)
        print("‚úÖ ONNX model ge√ßerli")
    except Exception as e:
        print(f"‚ö†Ô∏è ONNX doƒürulama uyarƒ±sƒ±: {e}")
    
    # 5. Quantization (opsiyonel ama √∂nerilir)
    print("\n[5/5] Quantization yapƒ±lƒ±yor (INT8)...")
    try:
        quantize_dynamic(
            ONNX_MODEL_PATH,
            ONNX_QUANTIZED_PATH,
            weight_type=QuantType.QUInt8
        )
        
        quantized_size_mb = os.path.getsize(ONNX_QUANTIZED_PATH) / (1024 * 1024)
        reduction = ((model_size_mb - quantized_size_mb) / model_size_mb) * 100
        print(f"‚úÖ Quantized model olu≈üturuldu: {ONNX_QUANTIZED_PATH}")
        print(f"   Quantized boyut: {quantized_size_mb:.2f} MB")
        print(f"   Boyut azalmasƒ±: %{reduction:.1f}")
    except Exception as e:
        print(f"‚ö†Ô∏è Quantization hatasƒ±: {e}")
        print("   Quantization olmadan devam edilebilir")
    
    print("\n" + "=" * 60)
    print("‚úÖ D√∂n√º≈üt√ºrme tamamlandƒ±!")
    print("=" * 60)
    print(f"\nüìÅ √áƒ±ktƒ± dosyalarƒ±:")
    print(f"   - Full model: {ONNX_MODEL_PATH}")
    if os.path.exists(ONNX_QUANTIZED_PATH):
        print(f"   - Quantized model: {ONNX_QUANTIZED_PATH} (√ñNERƒ∞LEN)")
    print(f"\nüí° Sonraki adƒ±m: Model dosyasƒ±nƒ± PharmaApp/assets/ klas√∂r√ºne kopyalayƒ±n")
    
    return True

if __name__ == "__main__":
    success = convert_to_onnx()
    if not success:
        print("\n‚ùå D√∂n√º≈üt√ºrme ba≈üarƒ±sƒ±z!")
        exit(1)

